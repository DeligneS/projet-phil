"""Student evaluation application using Streamlit and OpenAI."""

import asyncio
import os
from pathlib import Path
from dotenv import load_dotenv
import streamlit as st
from openai import AsyncOpenAI

# Load environment variables from .env file
load_dotenv()

from src.parsers import extract_student_submissions, parse_document, fetch_multiple_urls, parse_urls_from_text
from src.evaluation import (
    evaluate_all_students_async,
    evaluate_all_students_free_format_async,
    EvaluationResult,
)
from src.export import (
    create_combined_export_excel,
    create_combined_export_word,
    create_combined_export_free_format,
)

# Page configuration
st.set_page_config(
    page_title="√âvaluation des travaux √©tudiants",
    page_icon="üìö",
    layout="wide",
)

st.title("üìö √âvaluation des travaux √©tudiants")
st.markdown("---")


def load_default_system_prompt() -> str:
    """Load the default system prompt from file."""
    prompt_path = Path(__file__).parent / "prompts" / "system_prompt.txt"
    if prompt_path.exists():
        return prompt_path.read_text(encoding="utf-8")
    return ""


def parse_uploaded_files(files: list) -> str:
    """Parse and concatenate content from multiple uploaded files."""
    if not files:
        return ""

    contents = []
    for file in files:
        content = file.read()
        file.seek(0)  # Reset file pointer for potential re-read

        parsed = parse_document(file.name, content)
        if parsed:
            contents.append(f"=== {file.name} ===\n{parsed}")

    return "\n\n".join(contents)


# Initialize async OpenAI client
@st.cache_resource
def get_async_openai_client():
    """Get or create async OpenAI client."""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return None
    return AsyncOpenAI(api_key=api_key)


async_client = get_async_openai_client()

if not async_client:
    st.error(
        "‚ö†Ô∏è Cl√© API OpenAI non configur√©e. "
        "Veuillez d√©finir la variable d'environnement `OPENAI_API_KEY`."
    )
    st.stop()

# Three column layout for inputs
col1, col2, col3 = st.columns(3)

with col1:
    st.subheader("üìã Grille d'√©valuation")

    eval_grid_files = st.file_uploader(
        label="Fichiers (PDF, Word, Excel, TXT, HTML)",
        type=["pdf", "docx", "xlsx", "txt", "html", "htm"],
        accept_multiple_files=True,
        help="Uploadez un ou plusieurs fichiers contenant la grille d'√©valuation",
        key="eval_grid",
    )

    eval_grid_text = st.text_area(
        label="Ou saisissez directement la grille",
        placeholder="Collez ici votre grille d'√©valuation, crit√®res, bar√®me...",
        height=150,
        key="eval_grid_text",
        help="Vous pouvez combiner fichiers et texte",
    )

with col2:
    st.subheader("üìÅ Travaux √©tudiants")
    student_zip = st.file_uploader(
        label="Fichier ZIP des travaux",
        type=["zip"],
        accept_multiple_files=False,
        help="ZIP contenant un dossier par √©tudiant (nom du dossier = nom de l'√©tudiant)",
        key="student_zip",
    )

with col3:
    st.subheader("üìñ Base de connaissances")

    knowledge_files = st.file_uploader(
        label="Fichiers (PDF, Word, Excel, TXT, HTML)",
        type=["pdf", "docx", "xlsx", "txt", "html", "htm"],
        accept_multiple_files=True,
        help="Documents servant de r√©f√©rence pour l'√©valuation",
        key="knowledge",
    )

    knowledge_urls = st.text_area(
        label="URLs (une par ligne)",
        placeholder="https://exemple.com/cours\nhttps://autre-site.com/reference",
        height=80,
        key="knowledge_urls",
        help="Le contenu des pages web sera extrait automatiquement",
    )

    knowledge_text = st.text_area(
        label="Ou saisissez directement du contenu",
        placeholder="Collez ici des informations de r√©f√©rence, extraits de cours, d√©finitions...",
        height=150,
        key="knowledge_text",
        help="Vous pouvez combiner fichiers, URLs et texte",
    )

st.markdown("---")

# Output format section
st.subheader("üì§ Format de sortie")

OUTPUT_FORMATS = {
    "excel": "Excel (un fichier, une sheet par √©tudiant)",
    "word_structured": "Word structur√© (un document par √©tudiant, sections par crit√®re)",
    "word_free": "Word libre (format personnalis√©)",
}

output_format = st.radio(
    label="Choisissez le format de sortie",
    options=list(OUTPUT_FORMATS.keys()),
    format_func=lambda x: OUTPUT_FORMATS[x],
    horizontal=True,
)

# Show output format instructions for free format
output_format_instructions = ""
if output_format == "word_free":
    output_format_instructions = st.text_area(
        label="Instructions pour le format de sortie",
        placeholder="D√©crivez comment vous souhaitez que l'√©valuation soit format√©e...\n\nExemple:\n- Commencer par un r√©sum√© en 2-3 phrases\n- Lister les points forts\n- Lister les axes d'am√©lioration\n- Terminer par une note globale",
        height=150,
        help="Ces instructions d√©finissent la structure du document de sortie",
    )

st.markdown("---")

# Custom instructions section
st.subheader("üí¨ Instructions personnalis√©es")
default_prompt = load_default_system_prompt()

custom_instructions = st.text_area(
    label="Instructions suppl√©mentaires pour l'√©valuation",
    placeholder="Ajoutez ici des instructions sp√©cifiques pour guider l'√©valuation...",
    height=100,
    help="Ces instructions seront ajout√©es au prompt envoy√© au LLM",
)

# Advanced settings in expander
with st.expander("‚öôÔ∏è Param√®tres avanc√©s"):
    model = st.selectbox(
        "Mod√®le OpenAI",
        options=["gpt-5.2", "gpt-4.1", "gpt-4o"],
        index=0,
        help="Mod√®le √† utiliser pour l'√©valuation",
    )

    max_concurrent = st.slider(
        "√âvaluations parall√®les",
        min_value=1,
        max_value=1000,
        value=5,
        help="Nombre d'√©valuations simultan√©es (plus = plus rapide, mais attention aux limites de l'API)",
    )

    if st.checkbox("Modifier le prompt syst√®me", value=False):
        system_prompt = st.text_area(
            label="Prompt syst√®me",
            value=default_prompt,
            height=200,
        )
    else:
        system_prompt = default_prompt

st.markdown("---")

# Evaluation button and results
if st.button("üöÄ Lancer l'√©valuation", type="primary", use_container_width=True):
    # Validation
    has_eval_grid = eval_grid_files or eval_grid_text.strip()

    # For structured formats, we need an evaluation grid
    if output_format in ("excel", "word_structured") and not has_eval_grid:
        st.error("‚ùå Veuillez fournir une grille d'√©valuation (fichier ou texte).")
        st.stop()

    # For free format, we need output instructions
    if output_format == "word_free" and not output_format_instructions.strip():
        st.error("‚ùå Veuillez fournir des instructions pour le format de sortie.")
        st.stop()

    if not student_zip:
        st.error("‚ùå Veuillez uploader le fichier ZIP des travaux √©tudiants.")
        st.stop()

    # Parse evaluation grid (combine files + text)
    with st.spinner("Lecture de la grille d'√©valuation..."):
        eval_grid_parts = []

        # Parse uploaded files
        if eval_grid_files:
            files_content = parse_uploaded_files(eval_grid_files)
            if files_content:
                eval_grid_parts.append(files_content)

        # Add text input
        if eval_grid_text.strip():
            eval_grid_parts.append(f"=== Texte saisi ===\n{eval_grid_text.strip()}")

        eval_grid_content = "\n\n".join(eval_grid_parts)

    if not eval_grid_content:
        st.error("‚ùå Impossible de lire la grille d'√©valuation.")
        st.stop()

    # Parse knowledge base (combine files + URLs + text)
    with st.spinner("Lecture de la base de connaissances..."):
        knowledge_parts = []

        # Parse uploaded files
        if knowledge_files:
            files_content = parse_uploaded_files(knowledge_files)
            if files_content:
                knowledge_parts.append(files_content)

        # Fetch URL content
        if knowledge_urls.strip():
            urls = parse_urls_from_text(knowledge_urls)
            if urls:
                st.info(f"üåê R√©cup√©ration du contenu de {len(urls)} URL(s)...")
                url_contents = fetch_multiple_urls(urls)
                for url, content in url_contents:
                    knowledge_parts.append(f"=== {url} ===\n{content}")
                if len(url_contents) < len(urls):
                    st.warning(f"‚ö†Ô∏è {len(urls) - len(url_contents)} URL(s) n'ont pas pu √™tre r√©cup√©r√©es.")

        # Add text input
        if knowledge_text.strip():
            knowledge_parts.append(f"=== Texte saisi ===\n{knowledge_text.strip()}")

        knowledge_content = "\n\n".join(knowledge_parts)

    # Extract student submissions
    with st.spinner("Extraction des travaux √©tudiants..."):
        zip_content = student_zip.read()
        student_submissions = extract_student_submissions(zip_content)

    if not student_submissions:
        st.error("‚ùå Aucun travail d'√©tudiant trouv√© dans le ZIP.")
        st.stop()

    st.success(f"‚úÖ {len(student_submissions)} √©tudiants trouv√©s")

    # Parse all student works first (fast, synchronous)
    with st.spinner("Analyse des fichiers √©tudiants..."):
        parsed_submissions: dict[str, str] = {}
        for student_name, files in student_submissions.items():
            student_work_parts = []
            for filename, content in files:
                parsed = parse_document(filename, content)
                if parsed:
                    student_work_parts.append(f"=== {filename} ===\n{parsed}")

            if student_work_parts:
                parsed_submissions[student_name] = "\n\n".join(student_work_parts)
            else:
                st.warning(f"‚ö†Ô∏è Aucun fichier lisible pour {student_name}")

    if not parsed_submissions:
        st.error("‚ùå Aucun travail lisible trouv√©.")
        st.stop()

    # Progress tracking
    progress_bar = st.progress(0)
    status_text = st.empty()
    status_text.text(f"√âvaluation en cours (0/{len(parsed_submissions)})...")

    # Define progress callback for async evaluation
    def update_progress(completed: int, total: int, student_name: str):
        progress_bar.progress(completed / total)
        status_text.text(f"√âvaluation en cours ({completed}/{total}) - Termin√©: {student_name}")

    if output_format == "word_free":
        # Free format evaluation - async parallel processing
        results = asyncio.run(
            evaluate_all_students_free_format_async(
                client=async_client,
                student_submissions=parsed_submissions,
                evaluation_grid=eval_grid_content,
                knowledge_base=knowledge_content,
                system_prompt=system_prompt,
                output_format_instructions=output_format_instructions,
                custom_instructions=custom_instructions,
                model=model,
                max_concurrent=max_concurrent,
                progress_callback=update_progress,
            )
        )

        progress_bar.progress(1.0)
        status_text.text("√âvaluation termin√©e!")

        # Process results
        free_evaluations: list[tuple[str, str]] = []
        for student_name, result in results:
            if isinstance(result, Exception):
                st.error(f"‚ùå Erreur pour {student_name}: {result}")
            else:
                free_evaluations.append((student_name, result))

        if free_evaluations:
            st.success(f"‚úÖ {len(free_evaluations)} √©tudiants √©valu√©s avec succ√®s!")

            # Generate combined ZIP (Word + Markdown txt)
            with st.spinner("G√©n√©ration des documents..."):
                zip_buffer = create_combined_export_free_format(free_evaluations)

            # Download button
            st.download_button(
                label="üì• T√©l√©charger (ZIP: Word + Markdown)",
                data=zip_buffer,
                file_name="evaluations_etudiants.zip",
                mime="application/zip",
                type="primary",
            )

            # Show preview
            st.markdown("### üìù Aper√ßu des √©valuations")
            for student_name, content in free_evaluations:
                with st.expander(student_name):
                    st.markdown(content)
        else:
            st.error("‚ùå Aucune √©valuation n'a pu √™tre effectu√©e.")

    else:
        # Structured evaluation (Excel or Word structured) - async parallel processing
        results = asyncio.run(
            evaluate_all_students_async(
                client=async_client,
                student_submissions=parsed_submissions,
                evaluation_grid=eval_grid_content,
                knowledge_base=knowledge_content,
                system_prompt=system_prompt,
                custom_instructions=custom_instructions,
                model=model,
                max_concurrent=max_concurrent,
                progress_callback=update_progress,
            )
        )

        progress_bar.progress(1.0)
        status_text.text("√âvaluation termin√©e!")

        # Process results
        evaluations: list[EvaluationResult] = []
        for result in results:
            if isinstance(result, Exception):
                st.error(f"‚ùå Erreur: {result}")
            else:
                evaluations.append(result)

        if evaluations:
            st.success(f"‚úÖ {len(evaluations)} √©tudiants √©valu√©s avec succ√®s!")

            # Generate combined report based on output format (main format + markdown txt)
            if output_format == "excel":
                with st.spinner("G√©n√©ration des documents..."):
                    zip_buffer = create_combined_export_excel(evaluations)

                st.download_button(
                    label="üì• T√©l√©charger (ZIP: Excel + Markdown)",
                    data=zip_buffer,
                    file_name="evaluations_etudiants.zip",
                    mime="application/zip",
                    type="primary",
                )

            elif output_format == "word_structured":
                with st.spinner("G√©n√©ration des documents..."):
                    zip_buffer = create_combined_export_word(evaluations)

                st.download_button(
                    label="üì• T√©l√©charger (ZIP: Word + Markdown)",
                    data=zip_buffer,
                    file_name="evaluations_etudiants.zip",
                    mime="application/zip",
                    type="primary",
                )

            # Show summary
            st.markdown("### üìä R√©sum√© des √©valuations")
            summary_data = [
                {
                    "√âtudiant": e.student_name,
                    "Note": f"{e.note_finale} / {e.note_max}",
                }
                for e in evaluations
            ]
            st.dataframe(summary_data)

            # Expandable details for each student
            st.markdown("### üìù D√©tails par √©tudiant")
            for evaluation in evaluations:
                with st.expander(f"{evaluation.student_name} - {evaluation.note_finale}/{evaluation.note_max}"):
                    st.markdown("**Feedback g√©n√©ral:**")
                    st.write(evaluation.feedback_general)

                    st.markdown("**Crit√®res:**")
                    criteria_data = [
                        {
                            "Crit√®re": c.nom,
                            "Note": f"{c.note}/{c.note_max}",
                            "Commentaire": c.commentaire,
                        }
                        for c in evaluation.criteres
                    ]
                    st.dataframe(criteria_data)
        else:
            st.error("‚ùå Aucune √©valuation n'a pu √™tre effectu√©e.")
